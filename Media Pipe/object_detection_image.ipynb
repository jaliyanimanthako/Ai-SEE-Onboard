{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQM4eaD737WZ",
        "outputId": "448ae86c-f86f-4ec0-acc0-dc7cbbfd326c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Czd8di94C7p"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeGQOTST4R5x",
        "outputId": "d25d0af9-2de2-4f5e-9605-a5335ad7316d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-12-26 05:56:34--  https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/latest/efficientdet_lite0.tflite\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.163.207, 142.251.167.207, 142.251.16.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.163.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7254339 (6.9M) [application/octet-stream]\n",
            "Saving to: ‘efficientdet_lite0.tflite’\n",
            "\n",
            "\r          efficient   0%[                    ]       0  --.-KB/s               \refficientdet_lite0. 100%[===================>]   6.92M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-12-26 05:56:34 (87.7 MB/s) - ‘efficientdet_lite0.tflite’ saved [7254339/7254339]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/latest/efficientdet_lite0.tflite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "70qw_mQM6JPP"
      },
      "outputs": [],
      "source": [
        "model_path = \"C:/Users/Jaliya Nimantha/OneDrive/Desktop/Jaliya/AH LAB/Media Pipe/efficientdet.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-un3AdHD7YKV"
      },
      "outputs": [],
      "source": [
        "# Load the input image from an image file.\n",
        "mp_image = mp.Image.create_from_file('C:/Users/Jaliya Nimantha/OneDrive/Desktop/Jaliya/AH LAB/Media Pipe/image1.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGLPHr9h4Wh4",
        "outputId": "4edd3e2f-fe1d-4a17-85f6-6af181de8d9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.094635009765625\n"
          ]
        }
      ],
      "source": [
        "import mediapipe as mp\n",
        "\n",
        "#Base options for external assets\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "ObjectDetector = mp.tasks.vision.ObjectDetector\n",
        "ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "options = ObjectDetectorOptions(\n",
        "    base_options=mp.tasks.BaseOptions(model_asset_path=model_path),\n",
        "    max_results=5,\n",
        "    running_mode=VisionRunningMode.IMAGE ,\n",
        "    score_threshold = 0.5)\n",
        "\n",
        "with ObjectDetector.create_from_options(options) as detector:\n",
        "  start = time.time()\n",
        "  detection_result = detector.detect(mp_image)\n",
        "  print(time.time() - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8PuJA1g4n6V",
        "outputId": "5c8dca03-a2db-478c-d3df-4b1db572a4dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DetectionResult(detections=[Detection(bounding_box=BoundingBox(origin_x=670, origin_y=512, width=192, height=84), categories=[Category(index=None, score=0.61328125, display_name=None, category_name='car')], keypoints=[]), Detection(bounding_box=BoundingBox(origin_x=305, origin_y=503, width=133, height=95), categories=[Category(index=None, score=0.59375, display_name=None, category_name='car')], keypoints=[]), Detection(bounding_box=BoundingBox(origin_x=141, origin_y=445, width=138, height=119), categories=[Category(index=None, score=0.59375, display_name=None, category_name='truck')], keypoints=[]), Detection(bounding_box=BoundingBox(origin_x=535, origin_y=374, width=85, height=72), categories=[Category(index=None, score=0.546875, display_name=None, category_name='bus')], keypoints=[]), Detection(bounding_box=BoundingBox(origin_x=456, origin_y=469, width=96, height=70), categories=[Category(index=None, score=0.546875, display_name=None, category_name='car')], keypoints=[])])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detection_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEiGvd6XRn2m",
        "outputId": "70a27731-a135-4464-8164-2596a8e31957"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__annotations__',\n",
              " '__class__',\n",
              " '__dataclass_fields__',\n",
              " '__dataclass_params__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__match_args__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'create_from_pb2',\n",
              " 'detections',\n",
              " 'to_pb2']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(detection_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgLYsYjt830q",
        "outputId": "a9ed55b7-bdb0-4715-f979-d23e05086730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Detection(bounding_box=BoundingBox(origin_x=670, origin_y=512, width=192, height=84), categories=[Category(index=None, score=0.61328125, display_name=None, category_name='car')], keypoints=[]),\n",
              " Detection(bounding_box=BoundingBox(origin_x=305, origin_y=503, width=133, height=95), categories=[Category(index=None, score=0.59375, display_name=None, category_name='car')], keypoints=[]),\n",
              " Detection(bounding_box=BoundingBox(origin_x=141, origin_y=445, width=138, height=119), categories=[Category(index=None, score=0.59375, display_name=None, category_name='truck')], keypoints=[]),\n",
              " Detection(bounding_box=BoundingBox(origin_x=535, origin_y=374, width=85, height=72), categories=[Category(index=None, score=0.546875, display_name=None, category_name='bus')], keypoints=[]),\n",
              " Detection(bounding_box=BoundingBox(origin_x=456, origin_y=469, width=96, height=70), categories=[Category(index=None, score=0.546875, display_name=None, category_name='car')], keypoints=[])]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "detection_result.detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcwPKW5C879e",
        "outputId": "f75bb04a-0263-426a-c9c9-8f7b6cc09d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(detection_result.detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHS2rNke9Pqd",
        "outputId": "d89c634e-a660-48ce-92ed-052f3f94ccd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(detection_result.detections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz0W9imf9HBI",
        "outputId": "158a6197-7580-41bf-e894-9ffbbf0c31ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detection(bounding_box=BoundingBox(origin_x=670, origin_y=512, width=192, height=84), categories=[Category(index=None, score=0.61328125, display_name=None, category_name='car')], keypoints=[])\n",
            "\n",
            "\n",
            "Detection(bounding_box=BoundingBox(origin_x=305, origin_y=503, width=133, height=95), categories=[Category(index=None, score=0.59375, display_name=None, category_name='car')], keypoints=[])\n",
            "\n",
            "\n",
            "Detection(bounding_box=BoundingBox(origin_x=141, origin_y=445, width=138, height=119), categories=[Category(index=None, score=0.59375, display_name=None, category_name='truck')], keypoints=[])\n",
            "\n",
            "\n",
            "Detection(bounding_box=BoundingBox(origin_x=535, origin_y=374, width=85, height=72), categories=[Category(index=None, score=0.546875, display_name=None, category_name='bus')], keypoints=[])\n",
            "\n",
            "\n",
            "Detection(bounding_box=BoundingBox(origin_x=456, origin_y=469, width=96, height=70), categories=[Category(index=None, score=0.546875, display_name=None, category_name='car')], keypoints=[])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for data in detection_result.detections:\n",
        "  print(data)\n",
        "  print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WlLNYCgc9SE-"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import cv2\n",
        "\n",
        "# # Define the coordinates for the rectangle\n",
        "# start_point = (3, 2)\n",
        "# end_point = (56, 42)\n",
        "\n",
        "# # Load the image using the correct function\n",
        "# image = cv2.imread(\"C:/Users/Jaliya Nimantha/OneDrive/Desktop/Jaliya/AH LAB/Media Pipe/image.jpg\")\n",
        "\n",
        "# # Check if the image is loaded successfully\n",
        "# if image is None:\n",
        "#     print(\"Error: Image not found.\")\n",
        "# else:\n",
        "#     # Define the rectangle color and thickness\n",
        "#     TEXT_COLOR = (255, 0, 0)  # Red color\n",
        "#     thickness = 3  # Thickness of the rectangle border\n",
        "\n",
        "#     # Draw the rectangle on the image\n",
        "#     cv2.rectangle(image, start_point, end_point, TEXT_COLOR, thickness)\n",
        "\n",
        "#     # Display the image with the rectangle\n",
        "#     cv2.imshow(\"image\", image)\n",
        "\n",
        "#     # Wait for a key press and close the window\n",
        "#     cv2.waitKey(0)\n",
        "#     cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "-cnoGBbb9xTM",
        "outputId": "a100d8df-3711-4d83-e9f3-6dbaa8f7ae6c"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Load the image\n",
        "image_copy = cv2.imread(\"C:/Users/Jaliya Nimantha/OneDrive/Desktop/Jaliya/AH LAB/Media Pipe/image1.jpg\")\n",
        "\n",
        "#Ensure the visualize function and detection_result are defined correctly\n",
        "annotated_image = visualize(image_copy, detection_result)\n",
        "\n",
        "# Show the image\n",
        "cv2.imshow(\"Annotated Image\", annotated_image)\n",
        "\n",
        "# Wait for a key press and then close the window\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_objects(model_path, mp_image):\n",
        "    # Base options for external assets\n",
        "    BaseOptions = mp.tasks.BaseOptions\n",
        "    ObjectDetector = mp.tasks.vision.ObjectDetector\n",
        "    ObjectDetectorOptions = mp.tasks.vision.ObjectDetectorOptions\n",
        "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "    # Set up the options for the object detector\n",
        "    options = ObjectDetectorOptions(\n",
        "        base_options=BaseOptions(model_asset_path=model_path),\n",
        "        max_results=5,\n",
        "        running_mode=VisionRunningMode.IMAGE,\n",
        "        score_threshold=0.5\n",
        "    )\n",
        "\n",
        "    # Create the object detector from the options\n",
        "    with ObjectDetector.create_from_options(options) as detector:\n",
        "        start = time.time()\n",
        "        # Perform object detection\n",
        "        detection_result = detector.detect(mp_image)\n",
        "        print(\"Detection time:\", time.time() - start)\n",
        "\n",
        "    return detection_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# Open the webcam (0 is the default camera)\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Check if the webcam is opened correctly\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Could not open webcam.\")\n",
        "    exit()\n",
        "\n",
        "# Capture a single frame\n",
        "ret, frame = cap.read()\n",
        "\n",
        "# If frame is read correctly, display the frame\n",
        "if ret:\n",
        "    cv2.imshow('Captured Frame', frame)\n",
        "\n",
        "# Wait for a key press before closing\n",
        "cv2.waitKey(0)\n",
        "\n",
        "# Release the webcam and close the window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Example dictionary with corrected null -> None\n",
        "# data = {\n",
        "#     \"execution_count\": None,\n",
        "#     \"status\": \"success\",\n",
        "#     \"message\": \"Frame captured successfully\"\n",
        "# }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(frame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = cv2.imread(\"image1.jpg\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
